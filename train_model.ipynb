{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "This training and testing is largely based on the TensorFlow tutorial:\n",
    "[MNIST for Beginners](https://www.tensorflow.org/versions/r0.10/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_batch(data, labels, size):\n",
    "    indices = np.random.randint(0, data.shape[0], size)\n",
    "    return data[indices, :], labels[indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model\n",
    "\n",
    "* Read in the training data\n",
    "* Normalize the training data so that each feature value is in the range [0, 1]\n",
    "* Set up placeholders and variables to feed into the TensorFlow graph\n",
    "* Define the linear model\n",
    "* Define a loss function that will be minimized during training\n",
    "* Define which algorithm will be used to minimize the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = np.load('training_set.npy')\n",
    "training_set_shift = training_set - training_set.min(axis=0)\n",
    "training_set_norm = training_set_shift / training_set_shift.max(axis=0)\n",
    "training_labels = np.load('training_labels.npy')\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, training_set.shape[1]])\n",
    "W = tf.Variable(tf.zeros([training_set.shape[1], training_labels.shape[1]]))\n",
    "b = tf.Variable(tf.zeros([training_labels.shape[1]]))\n",
    "\n",
    "# The linear model y=W*x + b with softmax() to turn it into probabilities across the categories\n",
    "y = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# The known values\n",
    "y_ = tf.placeholder(tf.float32, [None, training_labels.shape[1]])\n",
    "\n",
    "# loss function\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "# print out cross entropy value to track convergence\n",
    "cross_entropy = tf.Print(cross_entropy, [cross_entropy], \"CrossE\", first_n=50)\n",
    "\n",
    "# how to train/optimize the model\n",
    "train_step = tf.train.GradientDescentOptimizer(0.8).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Training\n",
    "\n",
    "* Initialize the variables and create a TensorFlow session\n",
    "* Run the training step many times, each time grabbing a new batch of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(10000):\n",
    "  batch_xs, batch_ys = get_batch(training_set_norm, training_labels, 500)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "\n",
    "* Read and normalize the test data\n",
    "* Define the operation that calculates the accuracy, in this case it is the fraction of predictions that match the known labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.959167\n"
     ]
    }
   ],
   "source": [
    "test_set = np.load('test_set.npy')\n",
    "test_set_shift = test_set - test_set.min(axis=0)\n",
    "test_set_norm = test_set_shift / test_set_shift.max(axis=0)\n",
    "test_labels = np.load('test_labels.npy')\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x: test_set_norm, y_: test_labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "Saves all variables currently defined in the \"session\" which can be restored later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
