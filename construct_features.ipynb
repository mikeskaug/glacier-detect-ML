{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize\n",
    "\n",
    "**training_regions** is an object containing image subregions for selecting pixels used to train and test the model. The keys correspond to different images (each of which contain 7 spectral bands). Whithin each image, three subregions were manually selected that represent some category we hope to identify with the model, such as \"glacier\" or \"ocean\".\n",
    "\n",
    "**label_index** is an object that links category names, like \"glacier\", with the corresponding array index in the labels array. For now, there are only 3 categories, \"glacier\", \"ocean\", [\"clouds\", \"nodata_land\", \"sea_ice\", \"land_snow\"] => \"other\"\n",
    "\n",
    "**band_postfix** are the file endings corresponding to different spectral bands in each image. \"B1\", \"B2\", etc. indicate the different bands\n",
    "\n",
    "**features** are the variables calculated for each pixel. *x* and *y* are the geographic position of the pixel in projected coordinates. *I1* through *I7* are the pixel intensities in each of the seven spectal bands, B1 through B7\n",
    "\n",
    "**samples_per_region** is the number of randomly selected pixels from each subregion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_regions = {'LE70322482009163EDC00': {'glacier': [504805, 9012826, 507745, 9015186], # [minx, miny, maxx, maxy]\n",
    "                                              'ocean': [501577, 9033498, 505797, 9037183],\n",
    "                                              'clouds': [459838, 8986574, 464556, 8990694]},\n",
    "                    'LE70322482009195EDC00': {'glacier': [519943, 9014150, 520819, 9014914],\n",
    "                                              'ocean': [494791, 9017577, 503515, 9025196],\n",
    "                                              'nodata_land': [457395, 8959990, 474370, 8974814]},\n",
    "                    'LE70332482010173EDC00': {'glacier': [510865, 9028302, 517171, 9033809],\n",
    "                                              'ocean': [502533, 9038881, 509313, 9044802],\n",
    "                                              'sea_ice': [468803, 9024503, 473521, 9028623]},\n",
    "                    'LE70342482009177EDC00': {'glacier': [523709, 9011654, 524382, 9012241],\n",
    "                                              'ocean': [478029, 9026676, 493486, 9040175],\n",
    "                                              'land_snow': [529319, 9021811, 546625, 9036925]}}\n",
    "label_index = {'glacier': 0, 'ocean': 1, 'clouds': 2, 'nodata_land': 2, 'sea_ice': 2, 'land_snow': 2}\n",
    "band_postfix = ['_B1_clipped.TIF', '_B2_clipped.TIF', '_B3_clipped.TIF', '_B4_clipped.TIF',\n",
    "                '_B5_clipped.TIF', '_B6_VCID_2_clipped.TIF', '_B7_clipped.TIF']\n",
    "features = ['x', 'y', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7']\n",
    "train_samples_per_region = 2000\n",
    "test_samples_per_region = 100\n",
    "num_images = len(training_regions)\n",
    "num_categories = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct training and testing sets\n",
    "\n",
    "Iterate through each subregion in each image and construct the feature array (see *features* above) for each randomly selected pixel. The result is four tensors:\n",
    "\n",
    "**training_set** shape(number of pixels, number of features)\n",
    "```\n",
    "           x    y   I1  I2  I3  I4  I5  I6  I7\n",
    "pixel1\n",
    "pixel2\n",
    "pixel3\n",
    "                        ...etc\n",
    "```\n",
    "**training_labels** shape(number of pixels, number of categories)\n",
    "```\n",
    "        glacier(0) ocean(1) other(2)\n",
    "pixle1     0          0        1\n",
    "pixel2     0          0        1\n",
    "pixel3     1          0        0\n",
    "                ...etc\n",
    "```                \n",
    "is a tensor containing \"one-hot\" vectors for each pixel. It has a \"1\" in the positioin of the know category for that pixel, and 0s elsewhere.\n",
    "\n",
    "**test_set** is the same as training_set, but is based on a different random set of pixels and is used for testing the learned model\n",
    "\n",
    "**test_labels** again, the same as the training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_set = np.array([]).reshape(0, len(features))\n",
    "training_labels = np.array([]).reshape(0, num_categories)\n",
    "\n",
    "test_set = np.array([]).reshape(0, len(features))\n",
    "test_labels = np.array([]).reshape(0, num_categories)\n",
    "\n",
    "for key, value in training_regions.items():\n",
    "    for category, bounds in value.items():\n",
    "        train_x = np.random.randint(bounds[0], bounds[2], train_samples_per_region)\n",
    "        test_x = np.random.randint(bounds[0], bounds[2], test_samples_per_region)\n",
    "        train_y = np.random.randint(bounds[1], bounds[3], train_samples_per_region)\n",
    "        test_y = np.random.randint(bounds[1], bounds[3], test_samples_per_region)\n",
    "        \n",
    "        train_sub_set = np.zeros([train_samples_per_region, len(features)])\n",
    "        train_sub_set[:,0] = train_x\n",
    "        train_sub_set[:,1] = train_y\n",
    "\n",
    "        test_sub_set = np.zeros([test_samples_per_region, len(features)])\n",
    "        test_sub_set[:,0] = test_x\n",
    "        test_sub_set[:,1] = test_y\n",
    "\n",
    "        train_sub_labels = np.zeros([train_samples_per_region, num_categories])\n",
    "        test_sub_labels = np.zeros([test_samples_per_region, num_categories])\n",
    "        \n",
    "        for feature_index, band in enumerate(band_postfix):\n",
    "            path = './images/' + key + '/' + key + band\n",
    "            with rasterio.open(path) as dataset:\n",
    "                \n",
    "                for index, [x, y] in enumerate(train_sub_set[:,0:2]):\n",
    "                    [[I]] = list(dataset.sample([(x, y)]))\n",
    "                    train_sub_set[index, 2 + feature_index ] = I\n",
    "                    train_sub_labels[index, label_index[category]] = 1\n",
    "                \n",
    "                for index, [x, y] in enumerate(test_sub_set[:,0:2]):\n",
    "                    [[I]] = list(dataset.sample([(x, y)]))\n",
    "                    test_sub_set[index, 2 + feature_index] = I\n",
    "                    test_sub_labels[index, label_index[category]] = 1\n",
    "                     \n",
    "        training_set = np.vstack([training_set, train_sub_set])\n",
    "        training_labels = np.vstack([training_labels, train_sub_labels])\n",
    "        test_set = np.vstack([test_set, test_sub_set])\n",
    "        test_labels = np.vstack([test_labels, test_sub_labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save('training_set', training_set)\n",
    "np.save('training_labels', training_labels)\n",
    "np.save('test_set', test_set)\n",
    "np.save('test_labels', test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
